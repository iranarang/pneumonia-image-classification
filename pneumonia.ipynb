{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47069369-2687-46c7-b3bb-bf090edb4ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 files belonging to 2 classes.\n",
      "Found 5216 files belonging to 2 classes.\n",
      "Found 16 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "import numpy as np\n",
    "\n",
    "# already have split data into directories \n",
    "# add the paths \n",
    "train_data_dir = \"data/train/\"\n",
    "test_data_dir = \"data/test/\"\n",
    "val_data_dir = \"data/val/\"\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 150\n",
    "img_width = 150\n",
    "\n",
    "# rescale instance\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "\n",
    "# we do not set subset=both here because we do not want the test set split\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width), batch_size=batch_size\n",
    ")\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "test_rescale_ds = test_ds.map(lambda image,label:(rescale(image),label))\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width), batch_size=batch_size\n",
    ")\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "train_rescale_ds = train_ds.map(lambda image,label:(rescale(image),label))\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_data_dir,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width), batch_size=batch_size\n",
    ")\n",
    "\n",
    "# approach 1: manually rescale data --\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "val_rescale_ds = val_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb5249aa-9a3a-4523-bb27-c3da66eebc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch shape: (32, 150, 150, 3)\n",
      "Train labels shape: (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 16:28:19.392973: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_ds.take(1):  # Take one batch\n",
    "    print(\"Train batch shape:\", images.shape)  # Shape: (batch_size, height, width, channels)\n",
    "    print(\"Train labels shape:\", labels.shape)  # Shape: (batch_size,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c1c0995-4dc6-440e-8a53-5882e4fd7221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test batch shape: (32, 150, 150, 3)\n",
      "Test labels shape: (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 16:28:19.498655: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for images, labels in test_ds.take(1):\n",
    "    print(\"Test batch shape:\", images.shape)\n",
    "    print(\"Test labels shape:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be17e782-0d2b-4c6c-9c56-90ac9644f895",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get one batch of images and labels from the rescaled dataset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_rescale_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):  \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get one batch of images and labels from the rescaled dataset\n",
    "for images, labels in train_rescale_ds.take(1):  \n",
    "    X_train_batch = images.numpy()  # Convert to NumPy array\n",
    "    y_train_batch = labels.numpy()  # Convert labels to NumPy\n",
    "    break\n",
    "\n",
    "# Plot the first 5 images\n",
    "plt.figure(figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(X_train_batch[i])  # No need for uint8 conversion since values are [0,1]\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "print('Label for each of the above images:', y_train_batch[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809a0dba-c526-458b-b586-1ae97c34fe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_6 (Rescaling)     (None, 150, 150, 3)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 74, 74, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 36, 36, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 17, 17, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 36992)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               4735104   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4828610 (18.42 MB)\n",
      "Trainable params: 4828610 (18.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "input_shape=(150, 150, 3)\n",
    "num_classes = 2\n",
    "\n",
    "model = keras.Sequential([\n",
    "        layers.InputLayer(input_shape=input_shape),\n",
    "        layers.Rescaling(1./255),\n",
    "       \n",
    "        layers.Conv2D(32, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "       \n",
    "        layers.Conv2D(64, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "       \n",
    "        layers.Conv2D(128, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "       \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='sparse_categorical_crossentropy',  # Binary classification loss\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da550e88-e4b0-4b8b-ae04-d41e2a888a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "163/163 [==============================] - 52s 310ms/step - loss: 0.5857 - accuracy: 0.7410 - val_loss: 0.8762 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "163/163 [==============================] - 50s 305ms/step - loss: 0.5793 - accuracy: 0.7429 - val_loss: 0.7958 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "163/163 [==============================] - 50s 306ms/step - loss: 0.5798 - accuracy: 0.7429 - val_loss: 0.8684 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "163/163 [==============================] - 50s 304ms/step - loss: 0.5766 - accuracy: 0.7429 - val_loss: 0.8574 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "163/163 [==============================] - 50s 304ms/step - loss: 0.5742 - accuracy: 0.7429 - val_loss: 0.8610 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "163/163 [==============================] - 50s 307ms/step - loss: 0.5746 - accuracy: 0.7429 - val_loss: 0.8699 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "163/163 [==============================] - 51s 310ms/step - loss: 0.5740 - accuracy: 0.7429 - val_loss: 0.8684 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "163/163 [==============================] - 50s 304ms/step - loss: 0.5731 - accuracy: 0.7429 - val_loss: 0.8674 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "163/163 [==============================] - 49s 295ms/step - loss: 0.5729 - accuracy: 0.7429 - val_loss: 0.8776 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "163/163 [==============================] - 49s 301ms/step - loss: 0.5725 - accuracy: 0.7429 - val_loss: 0.8816 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "163/163 [==============================] - 49s 296ms/step - loss: 0.5716 - accuracy: 0.7429 - val_loss: 0.8568 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "163/163 [==============================] - 49s 296ms/step - loss: 0.5735 - accuracy: 0.7429 - val_loss: 0.8585 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "163/163 [==============================] - 51s 308ms/step - loss: 0.5722 - accuracy: 0.7429 - val_loss: 0.8630 - val_accuracy: 0.5000\n",
      "Epoch 14/20\n",
      "163/163 [==============================] - 50s 303ms/step - loss: 0.5728 - accuracy: 0.7429 - val_loss: 0.8948 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "163/163 [==============================] - 49s 298ms/step - loss: 0.5714 - accuracy: 0.7429 - val_loss: 0.8587 - val_accuracy: 0.5000\n",
      "Epoch 16/20\n",
      "163/163 [==============================] - 49s 299ms/step - loss: 0.5718 - accuracy: 0.7429 - val_loss: 0.8642 - val_accuracy: 0.5000\n",
      "Epoch 17/20\n",
      "163/163 [==============================] - 49s 298ms/step - loss: 0.5703 - accuracy: 0.7429 - val_loss: 0.8495 - val_accuracy: 0.5000\n",
      "Epoch 18/20\n",
      "163/163 [==============================] - 49s 297ms/step - loss: 0.5724 - accuracy: 0.7429 - val_loss: 0.8517 - val_accuracy: 0.5000\n",
      "Epoch 19/20\n",
      "163/163 [==============================] - 50s 303ms/step - loss: 0.5718 - accuracy: 0.7429 - val_loss: 0.8680 - val_accuracy: 0.5000\n",
      "Epoch 20/20\n",
      "163/163 [==============================] - 50s 306ms/step - loss: 0.5707 - accuracy: 0.7429 - val_loss: 0.8570 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_rescale_ds,\n",
    "    validation_data=val_rescale_ds,\n",
    "    epochs=20,  # Can be adjusted\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba47a86-546b-4b47-8b89-2be850afcba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 2s 74ms/step - loss: 0.7100 - accuracy: 0.6250\n",
      "Test Loss: 0.7100\n",
      "Test Accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test_rescale_ds)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8061fc-f7d8-4b59-b524-77a4f0e46832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.11/site-packages (from keras-tuner) (2.15.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from keras-tuner) (23.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from keras-tuner) (2.31.0)\n",
      "Collecting kt-legacy\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->keras-tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->keras-tuner) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->keras-tuner) (2023.11.17)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad54087-83db-457d-9367-f0cffeb8b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)))\n",
    "    \n",
    "    # Tune the number of Conv2D layers and filters\n",
    "    for i in range(hp.Int('conv_blocks', 1, 3)):\n",
    "        filters = hp.Int(f'filters_{i}', min_value=32, max_value=128, step=32)\n",
    "        model.add(layers.Conv2D(filters, (3,3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D())\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    # Tune number of units in dense layer\n",
    "    hp_units = hp.Int('dense_units', min_value=64, max_value=256, step=64)\n",
    "    model.add(layers.Dense(units=hp_units, activation='relu'))\n",
    "    \n",
    "    # Tune dropout rate\n",
    "    hp_dropout = hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    model.add(layers.Dropout(hp_dropout))\n",
    "    \n",
    "    model.add(layers.Dense(2, activation='softmax'))\n",
    "    \n",
    "    # Tune optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "    optimizer = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2922f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation metrics function\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, dataset):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for images, labels in dataset:\n",
    "        y_true.extend(labels.numpy())\n",
    "        preds = model.predict(images, verbose=0)\n",
    "        y_pred.extend(np.argmax(preds, axis=1))  # For multi-class\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, average='weighted'),\n",
    "        'recall': recall_score(y_true, y_pred, average='weighted'),\n",
    "        'f1': f1_score(y_true, y_pred, average='weighted')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27934d95-48f9-4826-b5db-28d38d6a333b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 14m 19s]\n",
      "val_accuracy: 0.9375\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 02h 42m 31s\n",
      "\n",
      "Best hyperparameters:\n",
      "- Conv blocks: 1\n",
      "- Filters (first block): 128\n",
      "- Dense units: 64\n",
      "- Dropout: 0.2\n",
      "- Optimizer: adam\n",
      "- Learning rate: 0.0001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_hps = None\n",
    "def run_tuning(tuner_type):\n",
    "    \"\"\"Run hyperparameter tuning with given strategy\"\"\"\n",
    "    if tuner_type == \"hyperband\":\n",
    "        tuner = kt.Hyperband(\n",
    "            model_builder,\n",
    "            objective='val_accuracy',\n",
    "            max_epochs=20,\n",
    "            factor=3,\n",
    "            project_name='pneumonia_hyperband'\n",
    "        )\n",
    "    elif tuner_type == \"bayesian\":\n",
    "        tuner = kt.BayesianOptimization(\n",
    "            model_builder,\n",
    "            objective='val_accuracy',\n",
    "            max_trials=30,\n",
    "            num_initial_points=10,\n",
    "            project_name='pneumonia_bayesian'\n",
    "        )\n",
    "    else:  # random\n",
    "        tuner = kt.RandomSearch(\n",
    "            model_builder,\n",
    "            objective='val_accuracy',\n",
    "            max_trials=30,\n",
    "            project_name='pneumonia_random'\n",
    "        )\n",
    "    \n",
    "    tuner.search(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=20,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)]\n",
    "    )\n",
    "    \n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    return evaluate_model(best_model, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run all tuners\n",
    "print(\"Running Hyperband tuning...\")\n",
    "hyperband_metrics = run_tuning(\"hyperband\")\n",
    "\n",
    "print(\"Running Bayesian tuning...\")\n",
    "bayesian_metrics = run_tuning(\"bayesian\")\n",
    "\n",
    "print(\"Running Random Search tuning...\")\n",
    "random_metrics = run_tuning(\"random\")\n",
    "\n",
    "print(f\"\"\"\n",
    "Best hyperparameters:\n",
    "- Conv blocks: {best_hps.get('conv_blocks')}\n",
    "- Filters (first block): {best_hps.get('filters_0')}\n",
    "- Dense units: {best_hps.get('dense_units')}\n",
    "- Dropout: {best_hps.get('dropout')}\n",
    "- Optimizer: {best_hps.get('optimizer')}\n",
    "- Learning rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a0511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame({\n",
    "    'Hyperband': hyperband_metrics,\n",
    "    'Bayesian': bayesian_metrics,\n",
    "    'Random': random_metrics\n",
    "}).T\n",
    "\n",
    "print(\"\\n=== Numerical Results ===\")\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa3e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizations\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Bar plot for all metrics\n",
    "metrics_df.plot(kind='bar', width=0.8)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('tuning_comparison.png')\n",
    "plt.show()\n",
    "\n",
    "# Radar chart for comprehensive comparison\n",
    "categories = list(metrics_df.columns)\n",
    "N = len(categories)\n",
    "\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "for method, row in metrics_df.iterrows():\n",
    "    values = row.values.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, linewidth=2, label=method)\n",
    "    ax.fill(angles, values, alpha=0.1)\n",
    "\n",
    "plt.xticks(angles[:-1], categories)\n",
    "plt.title('Tuning Method Comparison', y=1.1)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "plt.tight_layout()\n",
    "plt.savefig('radar_comparison.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb82ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_method = metrics_df['f1'].idxmax()\n",
    "print(f\"\\n✅ Best Method: {best_method} (F1-score: {metrics_df.loc[best_method, 'f1']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb110920-5e28-40ff-9b55-70d68eef9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild the best model with the best hyperparameters\n",
    "model = model_builder(best_hps) # maybe use best_model instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e69c44-3ade-4233-94fb-6f7d983a3051",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/best_pneumonia_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc789a33-8cf4-455f-819d-67839039191d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
